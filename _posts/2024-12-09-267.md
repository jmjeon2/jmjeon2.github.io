---
categories:
- AI/ML
- Notes
date: 2024-12-09 23:31:36 +0900
tags:
- langchain
- llm
- openai
title: '[LangChain] LangChain으로 텍스트 분류 모델 만들기'
uid: 267
---

## 개요

langchain을 사용하면 아주 손쉽게 텍스트를 분류하거나 label로 만들 수 있다.

이때 pydantic 패키지를 활용하면 되는데, pydantic 패키지는 python의 데이터를 구조화/직렬화/검증 할 수 있는 패키지이다.

주로 fastapi 등의 백엔드 프레임워크에서 데이터를 주고받을때의 스키마를 정의할때 사용하는데,

langchain에서도 활용하여 llm 모델을 호출해서 입력에 따라 원하는 스키마의 출력을 만들어 내는데 사용할 수 있다.

## 코드

예를 들어, 문장을 입력하고 해당 문장의 감정을 분석하고, aggressiveness를 분류하는 task를 langchain으로 해결해보고자 한다.

우선 필요한 모델에 따라 환경변수를 추가해준다. 나는 openai 와 langsmith api를 사용하기 위해 아래처럼 구성해두었다.

```python
# .env
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=<YOUR_LANGCHAIN_API_KEY>

OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>
```

그리고 환경변수를 적절히 가져올 수 있도록 load_dotenv() 를 호출해준다.

```python
from dotenv import load_dotenv

load_dotenv()
```

이제 pydantic의 BaseModel로 클래스 객체를 선언해준다. 이때 각 field는 원하는 출력의 설명을 description으로 명시해준다. 그럼 llm 모델이 이를 반영하여 적절한 값으로 해당 인스턴스를 반환해준다.

llm 모델은 openai의 ChatOpenAI 모델을 사용한다. 이때 위에서 선언한 BaseModel의 클래스 형태로 출력하기 위해서는 선언한 llm 모델에 `with_structured_output()` 함수를 추가해준다.

이 함수에는 아래 코드와 같이 BaseModel로 정의한 클래스명을 써주면 된다. 그리고 이 함수 사용시 llm 을 호출하면 항상 BaseModel의 객체가 반환된다.

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

tagging_prompt = ChatPromptTemplate.from_template(
    """
Extract the desired information from the following passage.

Only extract the properties mentioned in the 'Classification' function.

Passage:
{input}
"""
)

class Classification(BaseModel):
    sentiment: str = Field(description="The sentiment of the text")
    aggressiveness: int = Field(
        description="How aggressive the text is on a scale from 1 to 10"
    )
    language: str = Field(description="The language the text is written in")

# LLM
llm = ChatOpenAI(temperature=0, model="gpt-4o-mini").with_structured_output(
    Classification
)
```

이제 invoke함수를 통해 모델에 요청하여 어떻게 출력되는지 실제 테스트를 해본다.

```python
inp = "당신을 만나서 정말 기뻐요! 우리는 아주 좋은 친구가 될 것 같아요!"
prompt = tagging_prompt.invoke({"input": inp})
response = llm.invoke(prompt)

response
# Classification(sentiment='happy', aggressiveness=1, language='english')
```

위의 결과를 보면 sentiment=happy, aggressiveness=1, language=english로 분류된것을 알 수 있다.

추가로 response는 pydantic의 BaseModel 객체이기 때문에 .dict() 함수를 사용하면 dictionary 타입으로 쉽게 변경할 수 있다.

```python
inp = "I am very angry with you! I'm going to give you what you deserve!"
prompt = tagging_prompt.invoke({"input": inp})
response = llm.invoke(prompt)

response.dict()
# {'sentiment': 'sad', 'aggressiveness': 5, 'language': 'english'}
```

## enum 사용하기

위에서는 LLM이 판단하여 스키마에 따른 가장 적절한 응답을 채워서 반환해주었다. 하지만 응답의 범위를 제한하여 사용할 수 도 있다.

예를들면 여러 감정 중에서도 happy, neutral, sad 세가지만 분류하고 싶을 수 있다. 이런 경우에는 BaseModel을 구현할때 enum이라는 파라미터를 사용해서 출력의 값이 될 수 있는 것을 미리 지정할 수 있다.

아래 코드는 위와 다르게 `Field`와 `enum`이 사용되었다. 그럼 이제 감정은 3가지, aggressivness는 1~5까지, language는 5가지로 제한되게 답변을 해준다.

```python
class Classification(BaseModel):
    sentiment: str = Field(..., enum=["happy", "neutral", "sad"])
    aggressiveness: int = Field(
        ...,
        description="describes how aggressive the statement is, the higher the number the more aggressive",
        enum=[1, 2, 3, 4, 5],
    )
    language: str = Field(
        ..., enum=["spanish", "english", "french", "german", "korean"]
    )
```

> pydantic의 Field란?
> 
> 모델 필드의 속성을 정의할 때 사용한다. 이를 통해 필드에 대한 기본값, 유효성 검사, 메타데이터를 추가 지정할 수 있다.
> 
> 위에서 사용된 `Field(…, )` 는 해당 필드가 기본값은 없지만 반드시 입력이 필요한 필수값임을 의미한다.
{: .prompt-tip }


아래처럼 다시 llm을 with_structured_output으로 재정의 해주고 원하는 요청을 입력하면 잘 분류해서 출력해주는 것을 확인할 수 있다.

```python
tagging_prompt = ChatPromptTemplate.from_template(
    """
Extract the desired information from the following passage.

Only extract the properties mentioned in the 'Classification' function.

Passage:
{input}
"""
)

llm = ChatOpenAI(temperature=0, model="gpt-4o-mini").with_structured_output(
    Classification
)
```

```python
inp = "I am incredibly glad to have met you! I think we will be very good friends!"
prompt = tagging_prompt.invoke({"input": inp})
llm.invoke(prompt)
# Classification(sentiment='happy', aggressiveness=1, language='english')

inp = "I am very angry with you! I'm going to give you what you deserve!"
prompt = tagging_prompt.invoke({"input": inp})
llm.invoke(prompt)
# Classification(sentiment='sad', aggressiveness=5, language='english')

inp = "여기 날씨는 좋아. 외출할 때 코트만 입으면 돼."
prompt = tagging_prompt.invoke({"input": inp})
llm.invoke(prompt)
# Classification(sentiment='happy', aggressiveness=1, language='korean')
```

위의 결과를 보면 각각의 감정과 점수, 그리고 언어를 잘 인식해서 출력해준다.

## 결론

이러한 구조는 텍스트를 분류하거나 원하는 형태의 데이터 구조로 만드는 등 굉장히 다양하게 사용될 수 있다. 예전에는 데이터를 직접 학습하며 감정을 분류하는 등의 작업을 수행했는데 이제 텍스트 분류/태깅은 langchain과 openai api로 정말 쉽게 구현이 가능하다.

## 참고자료

[1] [https://python.langchain.com/docs/tutorials/classification/](https://python.langchain.com/docs/tutorials/classification/)

Uploaded by [N2C](https://github.com/jmjeon2/Notion2Chirpy)