---
categories:
- AI/ML
- Notes
date: 2024-10-15 22:15:30 +0900
math: true
tags:
- ai
- embedding
- faiss
- langchain
- llm
title: '[VectorDB] Langchain으로 FAISS 사용하기'
uid: 248
---

## 개요

지난번에 FAISS에서 임베딩 벡터들을 어떻게 저장하고 검색하는지 내부 알고리즘에 대해 알아봤다. 이번에는 자연어 관점에서 langchain 을 활용하여 어떻게 FAISS를 쓰는지 확인해본다.

## 설치 방법

langchain-community 패키지에 faiss를 활용할 수 있는 코드들이 포함되어있다. 또한 faiss 자체도 설치해주어야 한다. (gpu 사용시 gpu 버전으로 설치)

```bash
pip install langchain-community faiss-cpu
```

## VectorStore 생성

### 임베딩 모델 선언

- 우선 vector db를 사용하기 위해 embedding 모델을 선언해주어야 한다.
- embedding은 openai api나 huggingface를 사용해도 되고, 테스트 목적으로는 fake embedding 도 사용 가능하다.
- openai에서 사용 가능한 모델 중 `text-embedding-3-small` 모델을 사용한다.

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
```

> 각각의 데이터를 임베딩으로 만들때 같은 모델을 사용해야 검색이나 search가 가능하다.
{: .prompt-info }


### FAISS db 선언

- 처음 임베딩 벡터의 길이를 입력해주어야 한다.
- `faiss.IndexFlatL2`(바뀔 수 있음)로 index 객체를 생성하고 FAISS 객체에 embedding과, index를 같이 넣어준다.

```python
import faiss
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS

dimension = len(embeddings.embed_query("hello world"))
index = faiss.IndexFlatL2(dimension)

vector_store = FAISS(
    embedding_function=embeddings,
    index=index,
    docstore=InMemoryDocstore(),
    index_to_docstore_id={},
)
```

## DB에 데이터 추가하기

- 아래와 같이 Document 객체 기반으로 data를 추가할 수 있다.
- metadata는 해당 데이터의 다양한 값이 들어갈 수 있고, 추후에 이를 기반으로 필터링이 가능하다.
- vector_store.add_documents를 통해 여러 document를 한번에 추가할 수 있다.

```python
from uuid import uuid4

from langchain_core.documents import Document

document_1 = Document(
    page_content="I had chocalate chip pancakes and scrambled eggs for breakfast this morning.",
    metadata={"source": "tweet"},
)

document_2 = Document(
    page_content="The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.",
    metadata={"source": "news"},
)

document_3 = Document(
    page_content="Building an exciting new project with LangChain - come check it out!",
    metadata={"source": "tweet"},
)

document_4 = Document(
    page_content="Robbers broke into the city bank and stole $1 million in cash.",
    metadata={"source": "news"},
)

document_5 = Document(
    page_content="Wow! That was an amazing movie. I can't wait to see it again.",
    metadata={"source": "tweet"},
)

document_6 = Document(
    page_content="Is the new iPhone worth the price? Read this review to find out.",
    metadata={"source": "website"},
)

document_7 = Document(
    page_content="The top 10 soccer players in the world right now.",
    metadata={"source": "website"},
)

document_8 = Document(
    page_content="LangGraph is the best framework for building stateful, agentic applications!",
    metadata={"source": "tweet"},
)

document_9 = Document(
    page_content="The stock market is down 500 points today due to fears of a recession.",
    metadata={"source": "news"},
)

document_10 = Document(
    page_content="I have a bad feeling I am going to get deleted :(",
    metadata={"source": "tweet"},
)

documents = [
    document_1,
    document_2,
    document_3,
    document_4,
    document_5,
    document_6,
    document_7,
    document_8,
    document_9,
    document_10,
]
uuids = [str(uuid4()) for _ in range(len(documents))]

vector_store.add_documents(documents=documents, ids=uuids)
```

```python
# output: db에 저장된 각 document의 id가 출력된다.
['a32755d6-064f-4efb-9386-8ad3ba18e676',
 '631ddd3e-6225-4d68-8752-0e4b02502072',
 '2f392eef-8fb0-4a5b-a4fb-f8e0b6d90454',
 '370045e4-6a93-41c0-bfe5-221262a5a4c0',
 '3c94d4a5-c606-49bb-b79a-4fd9c053f8c6',
 'e80880f0-a6e3-4c39-9863-50e11b75ea3c',
 'f1fc68b4-6af7-4d2c-a10f-551c70a65a5c',
 '8f4aa88e-8d49-42fe-93b2-891e72feb15c',
 '7add4a31-4d90-4cbb-8d11-66676e25c72a',
 '44550686-cd35-4fb5-b446-871f5f19bdb7']
```

## DB의 데이터 삭제하기

- 아래와 같이 삭제하고자 하는 id를 리스트 형태로 입력하면 db에서 삭제할 수 있다.

```python
vector_store.delete(ids=[uuids[-1]])
# True
```

## DB 데이터 검색하기

내장된 함수를 이용하여 수동으로 입력 쿼리와 유사한 데이터를 검색하여 반환할 수 있다.

### similarity_search

유사도를 기반으로 입력 쿼리와 가장 유사한 data를 db 내에 찾아 반환한다.

**파라미터**

- query: 입력 쿼리 데이터
- k: 총 몇 개의 데이터를 검색할지
- filter: metadata 기반으로 필터링할 키워드 지정

```python
results = vector_store.similarity_search(
    "LangChain provides abstractions to make working with LLMs easy",
    k=2,
    filter={"source": "tweet"},
)
for res in results:
    print(f"* {res.page_content} [{res.metadata}]")
```

```
* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]
* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]
```

### similarity_search_with_score

similarity_search와 유사하지만 score 값을 추가적으로 함께 반환한다.

**파라미터**

- query: 입력 쿼리 데이터
- k: 총 몇 개의 데이터를 검색할지
- filter: metadata 기반으로 필터링할 키워드 지정

```python
results = vector_store.similarity_search_with_score(
    "Will it be hot tomorrow?", k=1, filter={"source": "news"}
)
for res, score in results:
    print(f"* [SIM={score:3f}] {res.page_content} [{res.metadata}]")
```

```
* [SIM=0.861662] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]
```

## Retriever로 사용하기

langchain에서는 chain 구조로 retriever를 만들어 한번에 각 구조를 통과시킨다. (프롬프트, 임베딩, LLM, 검색 등)

그러기 위해 vector_store도 retriever로 반환하여 `invoke` 함수로 한번에 실행이 가능하다.

**as_retriever**

- search_type: 검색하는 방법 입력
    - `similarity`: 유사도 기반 검색
    - `mmr`: Maximal Marginal Relevance 검색
- search_kwargs: 위의 similarity_search 함수에 들어가는 파라미터 입력

```python
retriever = vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 3})
retriever.invoke("Stealing from the bank is a crime", filter={"source": "news"})
```

```python
[Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]
```

## VectorStore 저장 및 불러오기

아래 `save_local`과 `load_local` 두 명령어를 통해 local 파일시스템에 faiss db를 저장하고 불러올 수 있다.

```python
# 저장하기
vector_store.save_local("faiss_index")

# 불러오기
new_vector_store = FAISS.load_local(
    "faiss_index", embeddings, allow_dangerous_deserialization=True
)
```

저장 후 새롭게 불러온 vector store로 similarity_search 검색을 하면 아래와 같이 잘 출력되는 것을 확인할 수 있다.

```python
docs = new_vector_store.similarity_search("qux")
```

```python
# output
[Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),
 Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),
 Document(metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),
 Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.')]
```

# 참고 자료

[1] [https://python.langchain.com/docs/integrations/vectorstores/faiss/#usage-for-retrieval-augmented-generation](https://python.langchain.com/docs/integrations/vectorstores/faiss/#usage-for-retrieval-augmented-generation)

[2] [https://wikidocs.net/234014](https://wikidocs.net/234014)

Uploaded by [N2C](https://github.com/jmjeon2/Notion2Chirpy)