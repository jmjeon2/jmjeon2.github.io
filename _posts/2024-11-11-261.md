---
categories:
- AI/ML
- Notes
date: 2024-11-11 21:17:59 +0900
tags:
- langchain
- llm
- openai
title: '[LangChain] 기초 사용법'
uid: 261
---

## LangChain 이란?

LangChain은 대형 언어 모델(LLM)과 외부 데이터 소스(e.g. 데이터베이스, API)를 결합해 AI 애플리케이션을 구축할 수 있도록 돕는 프레임워크이다. 주로 텍스트 처리, 검색, 생성과 같은 NLP 작업에서 활용되며, 유연한 체인 구성을 통해 복잡한 워크플로우를 만들 수 있다. 이를 통해 정보 검색 및 처리 자동화를 쉽게 구현할 수 있다.

## Langchain 설치

먼저 Langchain 및 기타 필요한 라이브러리를 설치한다. 아래 예제는 OpenAI 를 사용하기 때문에 langchain-openai 라이브러리도 같이 설치한다.

```bash
pip install langchain langchain-openai
```

## **환경변수 설정**

우선 Langchain을 사용하기 위해 `.env` 파일을 만들어 기본적인 환경변수 설정을 진행한다.

1. LangSmith를 사용하면 내가 어떤 요청을 어떻게 사용했는지 쉽게 알 수 있기 때문에 LangSmith 페이지에 가서 API 키 값을 생성해서 입력해준다.
2. OpenAI 키 값을 받아 입력해준다.

```
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=<KEY>

OPENAI_API_KEY=<KEY>
```

## OpenAI Chat 모델 사용하기

아래와 같이 ChatOpenAI 모델을 가져와 model을 선언해준다.

입력 파라미터로는 어떤 모델을 사용할지, temperature 등을 지정해 줄 수 있다.

아래 예시에서는 현재 날짜 기준(11/11) 가장 저렴한 `gpt-4o-mini` 모델을 사용했다. 

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini")
```

그럼 이제 system, user 메시지를 합쳐 모델에 요청해본다. 이미 Langchain에 사전에 정의된 `HumanMessage`, `SystemMessage`를 활용할 수도 있고, 아래 예시 코드처럼 튜플 형태의 메시지를 입력해도 된다.

모델 객체에 `.invoke()` 함수를 사용하면 원하는 쿼리(메시지)를 요청할 수 있다.

```python
from langchain_core.messages import HumanMessage, SystemMessage

messages = [
    SystemMessage(content="Translate the following from English into Korean."),
    HumanMessage(content="hi!"),
]

model.invoke(messages)
```

```python
# 메시지 객체를 이용하지 않고 Tuple 로 입력하기

messages = [
    ("system", "Translate the following from English into Korean."),
    ("user", "hi!"),
]

model.invoke(messages)
```

위의 어떤 코드를 실행해도 아래와 같은 출력이 나오게 된다.

```python
# Output
AIMessage(content='안녕하세요!', ...)
```

## 출력 Parser 활용

위의 출력은 content 외에도 다양한 값들이 함께 출력된다. 필요에 따라 원하는 값을 사용해도 되지만 대부분은 출력되는 메시지에 관심이 있을 것이다. 

따라서 Output Parser를 지정하면 원하는 내용만 출력하도록 할 수 있다.

![스크린샷 2024-11-11 오후 1.57.47.png](https://i.imgur.com/XTjj9qS.png)

우선 StrOutputParser를 확인해보면, AIMessage의 content 내용만 str 형태로 출력하게 해준다.

```python
from langchain_core.output_parsers import StrOutputParser

parser = StrOutputParser()

messages = [
    ("system", "Translate the following from English into Korean."),
    ("user", "hi!"),
]

result = model.invoke(messages)
parser.invoke(result)
# 안녕하세요!
```

위처럼 코드를 작성하면 parser로 선언한 변수를 .invoke() 해야 되기 때문에 model 요청 한번, parser 요청 한 번 총 두번의 코드를 작성해야 한다.

LangChain에서는 이를 이름에 걸맞게 Chain 형태로 연결하여 한번에 처리할 수 있도록 구성 되어 있다. chain 구성은 아주 쉽게 ‘`|`’ 기호(키보드 상 엔터 키 위에 있음)로 연결해주면 된다. 아래는 chain으로 구성한 예시 코드이다.

```python
chain = model | parser
chain.invoke(messages)
# 안녕하세요!
```

## 프롬프트 작성하기

최근의 LLM 모델을 사용할 때에 가장 중요한 것은 프롬프트 엔지니어링이다. LangChain에서는 프롬프트를 활용하기 위해 사전에 프롬프트 템플릿 구현체들을 정의해두었다. 프롬프트로 변경 되는 값들은 `{}` 기호로 안에 변수명을 써주고, 요청시에 해당 값을 입력해준다. 아래 예시 코드에서는 `ChatPromptTemplate`을 사용한다.

.invoke() 함수를 호출할 때 dictionary 형태로 프롬프트 안의 내용을 입력해준다. 이전 예시에서는 그냥 값 자체를 넣었는데, 프롬프트 템플릿 안에 변수가 여러개인 경우에는 아래처럼 입력을 dictionary 형태로 사용해주어야 한다.

```python
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_messages([
    ("system", "Translate the following into {language}:"), 
    ("user", "{text}")
])

result = prompt_template.invoke({"language": "korean", "text": "hi"})
# ChatPromptValue(messages=[SystemMessage(content='Translate the following into korean:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])
```

```python
result.to_messages()
# [SystemMessage(content='Translate the following into korean:', additional_kwargs={}, response_metadata={}),
#  HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]
```

위의 출력을 보면 SystemMessage와 HumanMessage에 각각 korean과 hi가 잘 들어간 것을 볼 수 있다. 이것도 프롬프트만을 invoke하면 프롬프트가 완성이 되고 model과 output parser는 각각 실행시켜 주어야 한다.

```python
prompt = prompt_template.invoke({"language": "korean", "text": "hi"})
model_output = model.invoke(prompt)
parsed_output = parser.invoke(model_output)
# 안녕하세요 !
```

하지만 위의 Chain 구성을 사용하면 더욱 간결하게 사용할 수 있다. 아래 코드처럼 model과 output parser를 chain 형태로 묶으면 한번에 실행시킬 수 있다. 

```python
chain = prompt_template | model | parser
chain.invoke({"language": "korean", "text": "hi"})
# 안녕하세요!
```

## LangSmith 확인

맨 처음 환경변수로 LangSmith의 Key값을 입력해주었다. LangSmith의 해당 프로젝트에 들어가보면 내가 어떤 요청을 했는지, 토큰은 얼마나 사용했고 비용은 얼마였는지 등에 대한 자세한 내역을 확인할 수 있다.

![스크린샷 2024-11-11 오후 1.56.03.png](https://i.imgur.com/8Q5yziB.png)

## 참고자료

[1] [https://python.langchain.com/docs/tutorials/llm_chain/](https://python.langchain.com/docs/tutorials/llm_chain/)

Uploaded by [N2C](https://github.com/jmjeon2/Notion2Chirpy)