---
categories:
- AI/ML
- Notes
date: 2020-10-20 23:02:44 +0900
math: true
tags:
- metrics
- 딥러닝
- 평가방법
title: '[딥러닝] Dice Coefficient 설명, pytorch 코드(segmentation 평가방법)'
uid: 99
---

## 개요

Dice score는 IoU와 같이 두 개의 영역 A, B가 얼마나 겹쳐지는 지를 나타내는 지표이다. Segmentation과 같은 기술을 사용할 때, GT와 예측된 영역 Pred를 비교할 때 사용할 수 있다.

## Dice Coefficient(Score)

### 공식

아래와 같이 A와 B의 겹쳐지는 정도로 계산할 수 있다. Dice 공식이 IoU와 다른 점은 분모에 교집합 부분(TP)이 한 번 더 더해지고, 분자에도 이와 마찬가지로 교집합(TP)이 한 번 더 더해진다.

$IoU=\dfrac{A\cap B}{A\cup B}$

$Dice = \dfrac{2*|A\cap B|}{|A| + |B|}= \dfrac{2*TP}{(TP+FP)+(TP+FN)}$

위 공식을 그림으로 나타내면 아래와 같다. 분모에는 두 개의 각 영역, 분자에는 겹쳐지는 영역의 2배이다.

![스크린샷 2021-10-25 오후 5.30.15.png](https://i.imgur.com/M60Qomp.png)

## Dice Loss

일반적으로 딥러닝에서 loss는 감소하도록 학습한다. 위의 공식 dice score는 값이 클수록 좋은 것이기 때문에 일반적으로 음의 값을 취해 아래와 같은 공식으로 loss function을 구현한다. 

두 영역이 같아질수록 dice score는 1에 가까워지고 dice loss는 0에 가까워지므로 학습이 잘 된다고 할 수 있다.

$dice\ loss=1-dice\ score$

## Python(Pytorch) 코드

```python
class DiceLoss(nn.Module):
    def __init__(self):
        super(DiceLoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):
        
        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리
        
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        
        intersection = (inputs * targets).sum()                            
        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  
        
        return 1 - dice 
				# return -torch.log(dice)
```

## 참고자료

[1] [https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2](https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2)